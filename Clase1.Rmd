---
title: "Control Estadístico de Procesos"
author: "Gustavo Ahumada"
output:
  pdf_document: default
  html_document:
    df_print: paged
  theme: united
  html_notebook: default
---

# Variables aleatorias discretas y continuas


## Variable aleatoria discreta
Una variable aleatoria discreta asume cada uno de sus valores cierta probabilidad. Cuando dos dados son lanzados, la probabilidad de que su suma sea $7$, escrita $f(x)= P(X=x)$, es igual $1/6$. La función que asigna la probabilidad a los valores de las variables aleatorias es llamada \textbf{función de densidad de probabilidad (pdf)} o \textbf{distribución de probabilidad}. Toda pdf debe satisfacer las siguientes condiciones:

1. $f(x)\geq 0$.
2. $\sum_{x}f(x)=1$.
3. $P(X=x)=f(x)$.

Hay muchos problemas en los cuales  deseamos calcular la probabilidad de que el valor observado de una variable aleatoria $X$ sea menor o igual que algún número real $x$. Al escribir  $F(X)=P(X	\leq x)$ para cualquier número real $x$, definimos la \textbf{distribución acumulada (cdf)} $F(X)$ de una variable aleatoria discreta $X$ con distribución $f(x)$. Se define como:

$F(X)=P(X	\leq x)=\sum_{t\leq x}f(x)$ para $-\infty<x<\infty$.

Tiene las siguientes propiedades:

1. $0\leq F(X)\leq 1$.
2. Si $a<b$, entonces $F(a)<F(b)$ para cualquier números reales $a$ y $b$. Por lo tanto, $F(X)$ es una función no decreciente de $x$.
3. $lim_{x\rightarrow\infty} F(X)=1$.
4. $lim_{x\rightarrow -\infty} F(X)=0$.


\textbf{Ejemplo 1} Lanzar una moneda equilibrada tres veces y sea la variable aleatoria $X$ el número de caras observadas en los tres intentos. 

\textbf{Solución} El espacio muestral para el experimento es:

$S= \{TTT, HTT, THT, HHT, TTH, HTH, THH, HHH\}$

La variable aleatoria $X$ puede tomar los valores de $0,1,2,$ y $3$ con probabilidades $\frac{1}{8}$, $\frac{3}{8}$, $\frac{3}{8}$, y $\frac{1}{8}$, respectivamente. Definir la cdf para $X$, $F(x)=P(X	\leq x)$ como sigue:

\begin{equation} 
f(n) = \left \{ \begin{matrix} 0 & \mbox{si }x<0,
\\ 1/8 & \mbox{si }0\leq x< 1,
\\ 4/8 & \mbox{si }1\leq x< 2,
\\ 7/8 & \mbox{si }2\leq x< 3,
\\ 1 & \mbox{si }x\ge 3 \end{matrix}\right. \nonumber
\end{equation} 

```{r}
opar <- par(no.readonly = TRUE)
library(MASS) 
par(mfrow=c(1,2), pty = "s")
S <- expand.grid(moneda1 = 0:1, moneda2 = 0:1, moneda3 = 0:1)
n.heads <- apply(S, 1, sum)
cbind(S, n.heads)
```

```{r}
T1 <- table(n.heads)/length(n.heads)
fractions(T1)
```


```{r}
plot(T1, xlab = "x", ylab = "P(X=x)", yaxt = "n", main = "PDF para X") +
axis(2, at =c(1/8, 3/8), labels = c("1/8", "3/8"), las = 1)
```


```{r}
plot(ecdf(n.heads), main = "CDF para X", ylab = "F(X)", xlab = "x",
     yaxt = "n") + 
  axis(2, at = c(1/8, 4/8, 7/8, 1), labels = c("1/8", "4/8", "7/8", "1"),
       las = 1) +
  segments(1, 1/8, 4/8, lty = 2) +
  text(2.6, 2.5/8, "P(X=1) = F(1)-F(0)") 
```


### Valor esperado
Una de las más importantes ideal acerca de resumir la información provista en una **pdf** es el valor esperado. Dada una variable aleatoria $X$ con una **pdf** $f(x)$, el **valor esperado** de la variable aleatoria $X$, escrito $E(X)$, es
\begin{equation} 
\mu = E(X) = \sum_{x}xf(x)  \nonumber
\end{equation} 
$E(X)$ peude ser denotada como $\mu$, porque $E(X)$ es la media de una variable aleatoria $X$.

**Ejemplo.** Un inspector de calidad muestrea un lote que contiene siete componentes; el lote contiene cuatro componentes buenos y tres defectuosos. El inspector toma una muestra de tres componentes. Encuentre el valor esperado del número de componentes buenos en esta muestra.

**Solución.** Sea $X$ el número de componentes buenos en la muestra. La distribución de probabilidad de $X$ es
\begin{equation} 
f(x) = \frac{\displaystyle\binom{4}{x} \displaystyle\binom{3}{3-x}}{\displaystyle\binom{7}{3}}, \quad x=0,1,2,3.  \nonumber
\end{equation} 

Unos simples cálculos dan $f(0)=1/35, f(1)=12/35,f(2)=18/35, f(3)=4/35$. Por lo tanto,
\begin{equation} 
E(X) = (0)\displaystyle\binom{1}{35} + (1)\displaystyle\binom{12}{35} + (2)\displaystyle\binom{18}{35} + (3)\displaystyle\binom{4}{35} = \frac{12}{7}=1.7.   \nonumber
\end{equation} 

```{r}
x <- c(0,1,2,3)
px <- c(0.029,0.343,0.514,0.114)
EX <- sum(x*px)
MP <- weighted.mean(x, px)
c(EX, MP)
```


### Varianza
El segundo momento de una variable aleatoria alrededor de la media es llamado la **varianza** de la distribución de $X$, o simplemente la varianza de $X$:
\begin{equation} 
\sigma^{2}_{x} = E[(X-\mu)]^2 = \sum_{x}(x-\mu)^{2}f(x)   \nonumber
\end{equation}
La raíz cuadrada de la varianza, $\sigma$, se llama **desviación estándar** de $X$.


## Variable aleatoria continua
Una variable aleatoria se llama **variable aleatoria continua** si puede tomar valores en una escala continua. A menudo los posibles valores de una variable continua son precisamente los mismos valores el espacio muestral continuo. Por ejemplo, la medición de la distancia que cierta marca de automóvil recorre en una pista de prueba con 5 litros de gasolina.

Una variable aleatoria continua tiene una probabilidad cero de tomar *exactamente* cualquiera de sus valores. Por lo tanto, su distribución de probabilidad no puede dar una forma tabular. Este tipo de variables aleatorias se caracterizan por:

- Toman valores en un intervalo (abierto o cerrado), es decir en un continuo.
- No tiene sentido calcular la probabilidad de que la v.a. adopte un valor particular, ya que es cero.
- Pero calculamos probabilidades en intervalos.
- Estas probabilidades son siempre áreas bajo curvas, estas curvas son las funciones de densidad.

La función de densidad de una variable aleatoria es una función que determinará una curva bajo la cual se calcularán las áreas = probabilidades en un intervalo.

**Definición**: Sea $X$ una variable aleatoria continua $x$ un número perteneciente al rango posible de valores de $X$, la función $f(x)$ es una **función de densidad de probabilidad** definida en el conjunto de los números reales $\mathbb{R}$, si

1. $f(x)\ge 0$, para todo $x \in \mathbb{R}$.
2. $\int_{-\infty}^{\infty}f(x)dx=1$.
3. $P(a<X>b)=\int_{a}^{b}f(x)dx$.

**Definición**: **La distribución acumulada (cdf)** $F(X)$ de una variable aleatoria $X$ con función de densidad $f(x)$ es

 \begin{equation}
 F(x) = P(X\leq x) = \int_{-\infty}^{\infty}f(t)dt \quad para \quad -\infty<x<\infty \nonumber
 \end{equation}.
 
 
 Dada la anterior definición, Siempre se pueden calcular probabilidades en un intervalo, y hay, por lo tanto dos maneras de hacerlo que son equivalentes: Sean dos valores, $a<b$
 
 \begin{equation}
 P(a<X>b)=\int_{a}^{b}f(x)dx \quad para \quad -\infty<x<\infty \nonumber
 \end{equation}
 \begin{equation}
 P(a<X>b)=F_{x}(b)-F_{x}(a) \quad para \quad -\infty<x<\infty \nonumber
 \end{equation}
 
 Es decir, directamente integrando la función de densidad o bien utilizando la cdf.
 
 
 **Ejemplo**. Suponer que $X$ es una variable aleatoria continua con **pdf** $f(x)$, donde
\begin{equation} 
f(x) = \left \{ \begin{matrix} c(1-x^{2}) & \mbox{si}-1<x\leq 1,
\\ 0 & \mbox{en otros casos.}\end{matrix}\right. \nonumber
\end{equation} 
 
a. Encontrar la constante $c$ que $f(x)$ es una **pdf** de la variable aleatoria $X$.
b. Encontrar la **cdf** para X.
c. Calcular $P(-0.5\le X\le 1)$.
d. Gráficar la **pdf** y **cdf**.

**Solución**
a. Empleando la propiedad $2$ de la definición de **pdf** 
\begin{equation}
1 = \int_{-\infty}^{\infty}f(x)dx \nonumber
\end{equation}

\begin{equation} 
\begin{split}
1 & = c\left(x - \frac{x^{3}}{3} \right)|_{-1}^{1} \\
  & = c\left(1 - \frac{1}{3} - (-1 - \frac{-1}{3})  \right) \\
  & = c\left(\frac{2}{3} -\frac{-2}{3}  \right) \\
c & = \frac34 \nonumber
\end{split}
\end{equation}  

b. Empleando la definición de **cdf** se verifica que

\begin{equation}
 F(x) = \left \{\begin{matrix} 0 & \mbox{si }x\le -1,
\\ \int_{-1}^{x} \frac34(1-t^2)dt) = \frac{-x^3}{4}+\frac{3x}{4}+\frac12 & \mbox{si } -1 < x\le 1,
\\ 1 & \mbox{si } x>1. \end{matrix}\right. \nonumber
 \end{equation}.
 
c.  Empleando la definición de distribución acumulada para la **pdf** de una vriable continua, tenemos

\begin{equation} 
\begin{split}
P(-0.5\le X\le 1) & = F(1) - F(-0.5) \\
  & = \left(\frac{-1^3}{4}+\frac{3*1}{4}+\frac{1}{2}\right) - \left(-\frac{-0.5^3}{4}+\frac{3*-0.5}{4}+\frac{1}{2}\right) \\
  & = c\left(\frac{2}{3} -\frac{-2}{3}  \right) \\
c & = \left(\frac{-1}{4}+\frac{3}{4}+\frac{1}{2}\right) - \left(\frac{1}{32}+\frac{-3}{8}+\frac{1}{2}\right) \\
  & = c\left(\frac{2}{3} -\frac{-2}{3}  \right) \\
  & = 1- \frac{5}{32}=\frac{27}{32} = 0.84375  \nonumber
\end{split}
\end{equation}  

d. El siguiente codigo genera la **pdf** y la **cdf** de $X$.
```{r}
f <- function(x) {
  y <- 3/4 * (1 - x^2)
  y[x < -1 | x > 1] <- 0
  return(y)
}
```


```{r}
F <- function(x) {
  y <- -x^3/4 + 3 * x/4 + 1/2
  y[x <= -1] <- 0
  y[x > 1] <- 1
  return(y)
}
```


```{r}
library(ggplot2)
graf <-ggplot(data.frame(x = c(-2, 2)), aes(x = x)) 
graf + stat_function(fun = f) + labs(x = "x", y = "f(x)", tittle = "PDF para X") 
graf + stat_function(fun = F) + labs(x = "x", y = "F(x)", tittle = "CDF para X")
```


### Valor esperado
Para variables aleatorias continuas, la definición asociada con la esperanza de una variable aleatoria $X$ o una función, digase $g(x)$, de $X$ son iguales para las variables aleatorias discretas, excepto que las sumatorias son reemplazadas con integrales. El **valor esperado** de una variable aleatoria continua $X$ es
\begin{equation} 
E(X) = \int_{-\infty}^{\infty} xf(x)dx.	   \nonumber
\end{equation}

### Varianza
\begin{equation} 
Var(X) = \sigma^{2}_{x} = E[(X- \mu)]^2 = \int_{-\infty}^{\infty} (x- \mu)^2f(x) dx.	   \nonumber
\end{equation}

**Ejemplo.** Dada la función
\begin{equation} 
f(x) = k, \quad -1<x<1    \nonumber
\end{equation}
de la variable aleatoria X,

a. Encontrar el valor de $k$ para hacer $f(x)$ una **pdf**. Emplear este $k$ para la parte (c) y (d).

b. Gráficar la **pdf** con ggplot2.

c. Encontrar la media de la distribución

d. Encontrar la varianza de la distribución.

**Solución**

a. Desde $\int_{-\infty}^{\infty} xf(x)dx$ debería ser 1 para que $f(x)$ sea una **pdf**, establecemos $\int_{-1}^{1} kdx = 1$ 

\begin{equation} 
\int_{-1}^{1} kdx = 1    \nonumber
\end{equation}
\begin{equation} 
kx |_{-1}^{1} = 1; \quad 2k = 1 \quad k = \frac{1}{2}    \nonumber
\end{equation}

b. Código para el gráfico
```{r}
x <- seq(-1, 1, length = 500)
y <- dunif(x, -1, 1)
DF <- data.frame(fx = y)
previous_theme <- theme_set(theme_bw())
ggplot(data = DF, aes(x = x, y = fx)) +
  geom_area(fill = "skyblue3") +
  labs(x = "x", y = "f(x)") +
  ylim(c(0, 1)) +
  theme_set(previous_theme)
```


c. La media de la distribución empleando la definición de valor esperado

\begin{equation} 
E[X] = \mu x = \int_{-1}^{1} \frac{1}{2} xdx     \nonumber
\end{equation}
\begin{equation} 
E[X] = \mu x = \frac{x^{2}}{4}|_{-1}^{1} = 0  \nonumber
\end{equation}

d. La varianza de la distribución empleando la definición de varianza

\begin{equation} 
Var[X] = \sigma^{2}_{x} = E[(X- \mu)^{2}] = \int_{-1}^{1} (x- \mu)^{2}f(x)dx     \nonumber
\end{equation}
\begin{equation} 
E[X] = \mu x = \frac{x^{3}}{6}|_{-1}^{1} = \frac{1}{3}  \nonumber
\end{equation}








